{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distance as dst\n",
    "import matplotlib.pyplot as plt\n",
    "import speech_recognition as sr\n",
    "\n",
    "from pathlib import Path\n",
    "#\n",
    "#\n",
    "#\n",
    "class Speech:\n",
    "    def __init__(self):\n",
    "        self.original = []\n",
    "        self.recognized = []\n",
    "        self.similarity = []\n",
    "\n",
    "        \n",
    "    def read_original(self, inFile) :\n",
    "        with open(inFile) as f :\n",
    "            content = f.readlines()\n",
    "            \n",
    "        for c in content :\n",
    "            self.original.append(c)\n",
    "\n",
    "            \n",
    "    def conv_audio(self, inDir) :\n",
    "        '''\n",
    "        https://realpython.com/python-speech-recognition/#author\n",
    "        '''\n",
    "        self.recognized = []\n",
    "        \n",
    "        trx = os.listdir(inDir)\n",
    "        trx.sort()\n",
    "        \n",
    "        r = sr.Recognizer()\n",
    "        \n",
    "        count = 1\n",
    "        for filename in trx :\n",
    "            wav_file = inDir + \"/\" + filename\n",
    "            track = sr.AudioFile(wav_file)\n",
    "            #\n",
    "            with track as source :\n",
    "                audio = r.record(source)\n",
    "                print(\"requesting track\", count)\n",
    "                self.recognized.append(r.recognize_google(audio))\n",
    "                print(\"processed track\", count)\n",
    "            count += 1\n",
    "            \n",
    "        \n",
    "    def comp_string(self) :\n",
    "        ''' \n",
    "        https://pypi.org/project/Distance/\n",
    "        '''\n",
    "        self.similarity = []\n",
    "        \n",
    "        for i in range(len(self.original)) :\n",
    "            src = self.original[i].split()\n",
    "            trgt = self.recognized[i].split()\n",
    "            self.similarity.append(dst.levenshtein(src, trgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting track 1\n",
      "processed track 1\n",
      "requesting track 2\n",
      "processed track 2\n",
      "requesting track 3\n",
      "processed track 3\n",
      "requesting track 4\n",
      "processed track 4\n",
      "requesting track 5\n",
      "processed track 5\n",
      "requesting track 6\n",
      "processed track 6\n",
      "requesting track 7\n",
      "processed track 7\n",
      "requesting track 8\n",
      "processed track 8\n",
      "requesting track 9\n",
      "processed track 9\n",
      "requesting track 10\n",
      "processed track 10\n",
      "requesting track 11\n",
      "processed track 11\n",
      "requesting track 12\n",
      "processed track 12\n",
      "requesting track 13\n",
      "processed track 13\n",
      "requesting track 14\n",
      "processed track 14\n",
      "requesting track 15\n",
      "processed track 15\n",
      "requesting track 16\n",
      "processed track 16\n",
      "requesting track 17\n",
      "processed track 17\n",
      "requesting track 18\n",
      "processed track 18\n",
      "requesting track 19\n",
      "processed track 19\n",
      "requesting track 20\n",
      "processed track 20\n",
      "requesting track 21\n",
      "processed track 21\n",
      "requesting track 22\n",
      "processed track 22\n",
      "requesting track 23\n",
      "processed track 23\n",
      "requesting track 24\n",
      "processed track 24\n",
      "requesting track 25\n",
      "processed track 25\n",
      "requesting track 1\n",
      "processed track 1\n",
      "requesting track 2\n",
      "processed track 2\n",
      "requesting track 3\n",
      "processed track 3\n",
      "requesting track 4\n",
      "processed track 4\n",
      "requesting track 5\n",
      "processed track 5\n",
      "requesting track 6\n",
      "processed track 6\n",
      "requesting track 7\n",
      "processed track 7\n",
      "requesting track 8\n",
      "processed track 8\n",
      "requesting track 9\n",
      "processed track 9\n",
      "requesting track 10\n",
      "processed track 10\n",
      "requesting track 11\n",
      "processed track 11\n",
      "requesting track 12\n",
      "processed track 12\n",
      "requesting track 13\n"
     ]
    },
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-ac52d642ed2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0meng_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"11-Chinese-Male\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomp_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mchi_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-cb7993aac8c1>\u001b[0m in \u001b[0;36mconv_audio\u001b[0;34m(self, inDir)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"requesting track\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"processed track\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mrecognize_google\u001b[0;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# return results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshow_all\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"alternative\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mUnknownValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"confidence\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alternative\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    s = Speech()\n",
    "    s.read_original(\"original.txt\")\n",
    "    #\n",
    "    s.conv_audio(\"08-English-male\")\n",
    "    s.comp_string()\n",
    "    eng_m = s.similarity\n",
    "    #\n",
    "    s.conv_audio(\"11-Chinese-Male\")\n",
    "    s.comp_string()\n",
    "    chi_m = s.similarity\n",
    "    \n",
    "    data = [eng_m, chi_m]\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.set_title(\"English vs. Chinese\")\n",
    "    ax1.boxplot(data, labels = [\"English\", \"Chinese\"])\n",
    "    ax1.set_ylabel(\"Data\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRAVEYARD ###\n",
    "'''\n",
    "if __name__ == '__main__':\n",
    "    s = Speech()\n",
    "    s.conv_audio(IN_DIR)\n",
    "    for line in s.recognized :\n",
    "        print(line)\n",
    "    \n",
    "    print(\"DONE!\")\n",
    "    \n",
    "\n",
    "\n",
    "def conv_audio(self, inDir) :\n",
    "    trx = os.listdir(inDir)\n",
    "    trx.sort()\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    folder = Path(inDir)\n",
    "    for filename in trx :\n",
    "        wav_file = folder / filename\n",
    "        track = sr.AudioFile(wav_file)\n",
    "        #\n",
    "        with track as source :\n",
    "            audio = r.record(source)\n",
    "            self.recognized.append(r.recognize_google(audio))\n",
    "                \n",
    "                \n",
    "                \n",
    "if __name__ == '__main__':\n",
    "    s = Speech()\n",
    "    s.read_original(\"original.txt\")\n",
    "    count = 0\n",
    "    for line in s.original :\n",
    "        print(count, line)\n",
    "        count += 1\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
